{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42561c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from ndlinear import NdLinear\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "nt_to_idx = {'A': 0, 'U': 1, 'G': 2, 'C': 3, 'N': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a6ed86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNAStruct(Dataset):\n",
    "    def __init__(self, seq_csv, labels_csv):\n",
    "        seq_df = pd.read_csv(seq_csv)\n",
    "        seq_map = {row['target_id']: row['sequence'].strip() for _, row in seq_df.iterrows()}\n",
    "\n",
    "        labels_df = pd.read_csv(labels_csv)\n",
    "        self.data = {}\n",
    "        for _, row in labels_df.iterrows():\n",
    "            target_id = row['ID'].rsplit('_', 1)[0]\n",
    "            idx = int(row['resid']) - 1\n",
    "            if target_id not in self.data:\n",
    "                self.data[target_id] = []\n",
    "            self.data[target_id].append((idx, row['resname'], row['x_1'], row['y_1'], row['z_1']))\n",
    "\n",
    "        self.samples = []\n",
    "        all_coords = []\n",
    "        for target_id in self.data:\n",
    "            dat = sorted(self.data[target_id], key=lambda x: x[0])\n",
    "            seq = seq_map[target_id]\n",
    "            coords = np.array([[x[2], x[3], x[4]] for x in dat], dtype=np.float32)\n",
    "            if len(seq) == len(coords) and np.isfinite(coords).all():\n",
    "                seq_idx = np.array([nt_to_idx.get(nt, 4) for nt in seq], dtype=np.int64)\n",
    "                self.samples.append((target_id, seq_idx, coords))\n",
    "                all_coords.append(coords)\n",
    "            else:\n",
    "                print(f\"Bad entry removed: {target_id} (len/coords/finite)\")\n",
    "\n",
    "        all_coords = np.concatenate(all_coords, axis=0)\n",
    "        self.mean = np.mean(all_coords, axis=0)\n",
    "        self.std = np.std(all_coords, axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        target_id, seq_idx, coords = self.samples[idx]\n",
    "        norm_coords = (coords - self.mean) / self.std\n",
    "        return torch.LongTensor(seq_idx), torch.tensor(norm_coords), len(seq_idx), target_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fdff36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate function\n",
    "def rna_collate(batch):\n",
    "    seqs, coords, lengths, ids = zip(*batch)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    seqs_padded = pad_sequence(seqs, batch_first=True, padding_value=4)\n",
    "    coords_padded = pad_sequence(coords, batch_first=True, padding_value=0)\n",
    "    return seqs_padded, coords_padded, lengths, ids\n",
    "\n",
    "\n",
    "# Model\n",
    "class RNA3DNet(nn.Module):\n",
    "    def __init__(self, vocab_size=5, emb_dim=128, num_layers=6, nhead=8, ff_dim=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=4)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=nhead, dim_feedforward=ff_dim, dropout=dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.ln = nn.LayerNorm(emb_dim)\n",
    "        self.fc = nn.Linear(emb_dim, 3)\n",
    "    def forward(self, seq, lengths):\n",
    "        x = self.embed(seq)\n",
    "        mask = (seq == 4)\n",
    "        x = self.encoder(x, src_key_padding_mask=mask)\n",
    "        x = self.ln(x)\n",
    "        coords = self.fc(x)\n",
    "        return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "203ea1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_points = 0\n",
    "\n",
    "    loss_fn = nn.MSELoss(reduction='none')\n",
    "\n",
    "    for seqs, coords, lengths, _ in val_loader:\n",
    "        seqs, coords, lengths = seqs.to(device), coords.to(device), lengths.to(device)\n",
    "        pred_coords = model(seqs, lengths)\n",
    "\n",
    "        mask = torch.arange(seqs.size(1), device=device)[None, :] < lengths[:, None]\n",
    "\n",
    "        mse = loss_fn(pred_coords, coords).sum(2)\n",
    "        loss = (mse * mask).sum() / mask.sum()\n",
    "        total_loss += loss.item() * mask.sum().item()\n",
    "        total_points += mask.sum().item()\n",
    "    rmsd = (total_loss / total_points) ** 0.5\n",
    "    return rmsd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, device, epochs=30, lr=1e-3, val_loader=None):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.8)\n",
    "    loss_fn = nn.MSELoss(reduction='none')\n",
    "    best_val_rmsd = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_points = 0\n",
    "        for seqs, coords, lengths, _ in dataloader:\n",
    "            seqs, coords, lengths = seqs.to(device), coords.to(device), lengths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred_coords = model(seqs, lengths)\n",
    "            mask = torch.arange(seqs.size(1), device=device)[None, :] < lengths[:, None]\n",
    "            mse = loss_fn(pred_coords, coords).sum(2)\n",
    "            loss = (mse * mask).sum() / mask.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * mask.sum().item()\n",
    "            total_points += mask.sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / total_points\n",
    "        print(f\"Epoch {epoch+1} Loss: {epoch_loss:.5f}\")\n",
    "\n",
    "        if val_loader is not None:\n",
    "            val_rmsd = validate(model, val_loader, device)\n",
    "            if val_rmsd is not None and val_rmsd < best_val_rmsd:\n",
    "                best_val_rmsd = val_rmsd\n",
    "                torch.save(model.state_dict(), 'best_model.pt')\n",
    "                print(f\"New best checkpoint (epoch {epoch+1}, RMSD {val_rmsd:.4f})\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    \n",
    "    torch.save(model.state_dict(), 'best_model.pt')\n",
    "    print(\"Final model saved as best_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4c62a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission Function\n",
    "def submission(model, seq_csv, submission_csv, device, mean, std):\n",
    "    seq_df = pd.read_csv(seq_csv)\n",
    "    model.eval()\n",
    "    submissions = []\n",
    "    for idx, row in seq_df.iterrows():\n",
    "        target_id, sequence = row['target_id'], row['sequence'].strip()\n",
    "        seq_idx = torch.LongTensor([nt_to_idx.get(nt, 4) for nt in sequence]).unsqueeze(0).to(device)\n",
    "        lengths = torch.tensor([len(sequence)]).to(device)\n",
    "        with torch.no_grad():\n",
    "            coords = model(seq_idx, lengths)[0][:len(sequence)].cpu().numpy()\n",
    "            coords = coords * std + mean\n",
    "        for i, (nt, (x, y, z)) in enumerate(zip(sequence, coords)):\n",
    "            id_out = f\"{target_id}_{i+1}\"\n",
    "            submissions.append({\n",
    "                \"ID\": id_out,\n",
    "                \"resname\": nt,\n",
    "                \"resid\": i+1,\n",
    "                \"x_1\": x, \"y_1\": y, \"z_1\": z,\n",
    "                \"x_2\": 0.0, \"y_2\": 0.0, \"z_2\": 0.0,\n",
    "                \"x_3\": 0.0 \n",
    "            })\n",
    "    sub_df = pd.DataFrame(submissions)\n",
    "    sub_df.to_csv(submission_csv, index=False)\n",
    "    print(f\"Submission CSV written: {submission_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19a566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 3.67628\n",
      "New best checkpoint (epoch 1, RMSD 1.7766)\n",
      "Epoch 2 Loss: 3.22439\n",
      "New best checkpoint (epoch 2, RMSD 1.7514)\n",
      "Epoch 3 Loss: 3.20590\n",
      "New best checkpoint (epoch 3, RMSD 1.7487)\n",
      "Epoch 4 Loss: 3.19225\n",
      "New best checkpoint (epoch 4, RMSD 1.7398)\n",
      "Epoch 5 Loss: 3.17232\n",
      "Epoch 6 Loss: 3.15293\n",
      "New best checkpoint (epoch 6, RMSD 1.7386)\n",
      "Epoch 7 Loss: 3.10487\n",
      "New best checkpoint (epoch 7, RMSD 1.7353)\n",
      "Epoch 8 Loss: 3.10308\n",
      "New best checkpoint (epoch 8, RMSD 1.7350)\n",
      "Epoch 9 Loss: 3.11389\n",
      "Epoch 10 Loss: 3.08420\n",
      "New best checkpoint (epoch 10, RMSD 1.7345)\n",
      "Epoch 11 Loss: 3.09478\n",
      "Epoch 12 Loss: 3.06061\n",
      "New best checkpoint (epoch 12, RMSD 1.7328)\n",
      "Epoch 13 Loss: 3.06469\n",
      "Epoch 14 Loss: 3.06521\n",
      "Epoch 15 Loss: 3.05548\n",
      "Epoch 16 Loss: 3.08788\n",
      "Epoch 17 Loss: 3.04885\n",
      "Epoch 18 Loss: 3.04073\n",
      "Epoch 19 Loss: 3.02710\n",
      "Epoch 20 Loss: 3.01367\n",
      "Epoch 21 Loss: 3.01015\n",
      "Epoch 22 Loss: 3.01390\n",
      "Epoch 23 Loss: 3.00518\n",
      "Epoch 24 Loss: 2.99706\n",
      "Epoch 25 Loss: 2.98457\n",
      "Epoch 26 Loss: 3.00606\n",
      "Epoch 27 Loss: 2.99619\n",
      "Epoch 28 Loss: 2.99636\n",
      "Epoch 29 Loss: 2.99023\n",
      "Epoch 30 Loss: 2.98661\n",
      "Final model saved as rna3dnet_baseline.pt\n",
      "Submission CSV written: rna-folding/submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pradip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    }
   ],
   "source": [
    "#Training \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = RNAStruct(\"rna-folding/train_sequences_clean.csv\", \"rna-folding/train_labels_clean.csv\")\n",
    "val_dataset = RNAStruct(\"rna-folding/validation_sequences.csv\", \"rna-folding/validation_labels.csv\")\n",
    "\n",
    "mean = train_dataset.mean\n",
    "std = train_dataset.std\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=rna_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=rna_collate)\n",
    "\n",
    "model = RNA3DNet().to(device)\n",
    "train_model(model, train_loader, device, epochs=30, lr=1e-5, val_loader=val_loader)\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "# Generate predictions\n",
    "submission(model, \"rna-folding/test_sequences.csv\", \"rna-folding/submission.csv\", device, mean, std)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
