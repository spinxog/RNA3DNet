{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42561c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import optuna\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "nt_to_idx = {'A': 0, 'U': 1, 'G': 2, 'C': 3, 'N': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "16c6b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    vocab_size = len(nt_to_idx)\n",
    "    max_len = 512\n",
    "    emb_dim = 128\n",
    "    num_layers = 4\n",
    "    nhead = 16\n",
    "    ff_dim = 1024\n",
    "    dropout = 0.10055310921251336\n",
    "    batch_size = 4\n",
    "    epochs = 5\n",
    "    lr = 0.0006706453668054184\n",
    "    pad_idx = 4\n",
    "    \n",
    "    use_scheduler = True\n",
    "    seed = 42\n",
    "\n",
    "    def set_seed(self):\n",
    "        torch.manual_seed(self.seed)\n",
    "        torch.cuda.manual_seed_all(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        random.seed(self.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "config = Config()\n",
    "config.set_seed()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\"cpu\")\n",
    "torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5a6ed86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNAStruct(Dataset):\n",
    "    def __init__(self, seq_csv, labels_csv, msa_dir=\"MSA\", mean=None, std=None, normalize=True, train_mode=False, noise_std=0.0):\n",
    "        import pandas as pd\n",
    "        seq_df = pd.read_csv(seq_csv)\n",
    "        seq_map = {row['target_id']: row['sequence'].strip() for _, row in seq_df.iterrows()}\n",
    "        self.train_mode = train_mode\n",
    "        self.noise_std = noise_std\n",
    "        self.msa_dir = msa_dir\n",
    "\n",
    "        labels_df = pd.read_csv(labels_csv)\n",
    "        self.data = {}\n",
    "        for _, row in labels_df.iterrows():\n",
    "            target_id = row['ID'].rsplit('_', 1)[0]\n",
    "            idx = int(row['resid']) - 1\n",
    "            if target_id not in self.data:\n",
    "                self.data[target_id] = []\n",
    "            self.data[target_id].append((idx, row['resname'], row['x_1'], row['y_1'], row['z_1']))\n",
    "\n",
    "        self.samples = []\n",
    "        for target_id in self.data:\n",
    "            dat = sorted(self.data[target_id], key=lambda x: x[0])\n",
    "            seq = seq_map[target_id]\n",
    "            coords = np.array([[x[2], x[3], x[4]] for x in dat], dtype=np.float32)\n",
    "            if len(seq) == len(coords) and np.isfinite(coords).all():\n",
    "                seq_idx = np.array([nt_to_idx.get(nt, 4) for nt in seq], dtype=np.int64)\n",
    "                base_onehot = np.eye(4)[seq_idx]\n",
    "                rel_pos = np.arange(len(seq), dtype=np.float32) / (max(len(seq) - 1, 1))\n",
    "                rel_pos = rel_pos[:, None]\n",
    "                msa_profile = self._load_msa_profile(target_id, seq)  # (L, 4)\n",
    "                features = np.concatenate([base_onehot, rel_pos, msa_profile], axis=1)  # shape (L,9)\n",
    "                self.samples.append((target_id, seq_idx, coords, features))\n",
    "            else:\n",
    "                print(f\"Bad entry removed: {target_id}\")\n",
    "\n",
    "        all_coords = np.concatenate([coords for _, _, coords, _ in self.samples], axis=0)\n",
    "        self.mean = mean if mean is not None else all_coords.mean(axis=0)\n",
    "        self.std = std if std is not None else all_coords.std(axis=0)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target_id, seq_idx, coords, features = self.samples[idx]\n",
    "        length = len(seq_idx)\n",
    "        if self.normalize:\n",
    "            mean = self.mean.numpy() if isinstance(self.mean, torch.Tensor) else self.mean\n",
    "            std = self.std.numpy() if isinstance(self.std, torch.Tensor) else self.std\n",
    "            norm_coords = (coords - mean) / std\n",
    "            if self.train_mode and self.noise_std > 0:\n",
    "                norm_coords = norm_coords + np.random.normal(0, self.noise_std, size=norm_coords.shape).astype(np.float32)\n",
    "            return (\n",
    "                torch.LongTensor(seq_idx),\n",
    "                torch.tensor(norm_coords, dtype=torch.float32),\n",
    "                length,\n",
    "                target_id,\n",
    "                torch.tensor(features, dtype=torch.float32)\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                torch.LongTensor(seq_idx),\n",
    "                torch.tensor(coords, dtype=torch.float32),\n",
    "                length,\n",
    "                target_id,\n",
    "                torch.tensor(features, dtype=torch.float32)\n",
    "            )\n",
    "\n",
    "    def get_mean_std(self,):\n",
    "        return self.mean, self.std\n",
    "\n",
    "    def _load_msa_profile(self, target_id, seq):\n",
    "        msa_path = os.path.join(self.msa_dir, f\"{target_id}.MSA.fasta\")\n",
    "        profile = np.zeros((len(seq), 4), dtype=np.float32)\n",
    "        if not os.path.exists(msa_path):\n",
    "            return profile\n",
    "        msa = [str(record.seq) for record in SeqIO.parse(msa_path, 'fasta')]\n",
    "        nt_to_col = {'A':0, 'C':1, 'G':2, 'U':3}\n",
    "        for i, s in enumerate(zip(*msa)):\n",
    "            total = 0\n",
    "            for nt in 'ACGU':\n",
    "                c = s.count(nt)\n",
    "                profile[i, nt_to_col[nt]] = c\n",
    "                total += c\n",
    "            if total > 0:\n",
    "                profile[i] /= total\n",
    "        return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_for_test(seq, target_id, msa_dir=\"MSA\"):\n",
    "    seq_idx = np.array([nt_to_idx.get(nt, 4) for nt in seq], dtype=np.int64)\n",
    "    base_onehot = np.eye(4)[np.clip(seq_idx,0,3)]\n",
    "    rel_pos = np.arange(len(seq), dtype=np.float32) / (max(len(seq) - 1, 1))\n",
    "    rel_pos = rel_pos[:, None]\n",
    "    profile = np.zeros((len(seq), 4), dtype=np.float32)\n",
    "    msa_path = os.path.join(msa_dir, f\"{target_id}.MSA.fasta\")\n",
    "    if os.path.exists(msa_path):\n",
    "        from Bio import SeqIO\n",
    "        msa = [str(record.seq) for record in SeqIO.parse(msa_path, 'fasta')]\n",
    "        nt_to_col = {'A':0, 'C':1, 'G':2, 'U':3}\n",
    "        for i, s in enumerate(zip(*msa)):\n",
    "            total = 0\n",
    "            for nt in 'ACGU':\n",
    "                c = s.count(nt)\n",
    "                profile[i, nt_to_col[nt]] = c\n",
    "                total += c\n",
    "            if total > 0:\n",
    "                profile[i] /= total\n",
    "    features = np.concatenate([base_onehot, rel_pos, profile], axis=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8f43ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        device = x.device\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, self.d_model, 2, device=device).float() * (-math.log(10000.0) / self.d_model)\n",
    "        )\n",
    "        pe = torch.zeros(seq_len, self.d_model, device=device)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return x + pe.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2b99463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rna_collate(batch):\n",
    "    seqs, coords, lengths, target_ids, features = zip(*batch)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    seqs_padded = pad_sequence(seqs, batch_first=True, padding_value=4)\n",
    "    coords_padded = pad_sequence(coords, batch_first=True, padding_value=0)\n",
    "    features_padded = pad_sequence(features, batch_first=True, padding_value=0)\n",
    "    return seqs_padded, coords_padded, lengths, target_ids, features_padded\n",
    "\n",
    "class RNA3DNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(config.vocab_size, config.emb_dim, padding_idx=config.pad_idx)\n",
    "        self.extra_linear = nn.Linear(9, 32)\n",
    "        self.extra_bn = nn.BatchNorm1d(32)\n",
    "\n",
    "        self.pos_enc = PositionalEncoding(config.emb_dim + 32)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config.emb_dim + 32, \n",
    "            nhead=config.nhead, \n",
    "            dim_feedforward=config.ff_dim * 2,\n",
    "            dropout=config.dropout, \n",
    "            batch_first=True, \n",
    "            norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config.num_layers + 2) # More layers\n",
    "\n",
    "        self.ln = nn.LayerNorm(config.emb_dim + 32)\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.emb_dim + 32, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "    def forward(self, seq, lengths, features, noise_std=0.0):\n",
    "        x = self.embed(seq)\n",
    "        batch_size, seq_len, _ = features.size()\n",
    "        extra = self.extra_linear(features).view(batch_size * seq_len, -1)\n",
    "        extra = self.extra_bn(extra).view(batch_size, seq_len, -1)\n",
    "        x = torch.cat([x, extra], dim=-1)\n",
    "\n",
    "        if noise_std > 0 and self.training:\n",
    "            x = x + torch.randn_like(x) * noise_std\n",
    "\n",
    "        x = self.pos_enc(x)\n",
    "        mask = (seq == config.pad_idx)\n",
    "\n",
    "        x = self.encoder(x, src_key_padding_mask=mask)\n",
    "        x = self.ln(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        coords = self.fc2(x)\n",
    "        return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0b202ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tm_score(pred_coords, true_coords, Lref=None):\n",
    "    assert pred_coords.shape == true_coords.shape\n",
    "    L = pred_coords.shape[0]\n",
    "    Lref = Lref if Lref is not None else L\n",
    "    dists = np.linalg.norm(pred_coords - true_coords, axis=1)\n",
    "    \n",
    "    # d0 depends on Lref\n",
    "    if Lref >= 30:\n",
    "        d0 = 1.24 * (Lref - 15) ** (1/3) - 1.8\n",
    "    elif Lref >= 24:\n",
    "        d0 = 0.7\n",
    "    elif Lref >= 20:\n",
    "        d0 = 0.6\n",
    "    elif Lref >= 16:\n",
    "        d0 = 0.5\n",
    "    elif Lref >= 12:\n",
    "        d0 = 0.4\n",
    "    else:\n",
    "        d0 = 0.3\n",
    "\n",
    "    score = (1 / Lref) * np.sum(1 / (1 + (dists / d0) ** 2))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dcafcb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kabsch_align(P, Q):\n",
    "    C = np.dot(P.T, Q)\n",
    "    V, S, Wt = np.linalg.svd(C)\n",
    "    d = (np.linalg.det(V) * np.linalg.det(Wt)) < 0.0\n",
    "    if d:\n",
    "        V[:, -1] = -V[:, -1]\n",
    "    U = np.dot(V, Wt)\n",
    "    return np.dot(P, U)\n",
    "\n",
    "\n",
    "\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_pts, total_rmsd, total_tm = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for seqs, coords, lengths, _, features  in dataloader:\n",
    "            seqs = seqs.to(device)\n",
    "            coords = coords.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            features = features.to(device)\n",
    "            pred_coords = model(seqs, lengths, features=features)\n",
    "            for i in range(seqs.size(0)):\n",
    "                L = lengths[i].item()\n",
    "                pred_i = pred_coords[i, :L].cpu().numpy()\n",
    "                true_i = coords[i, :L].cpu().numpy()\n",
    "                pred_aligned = kabsch_align(pred_i - pred_i.mean(axis=0), true_i - true_i.mean(axis=0))\n",
    "\n",
    "                dists = np.linalg.norm(pred_aligned - true_i, axis=1)\n",
    "                rmsd = np.sqrt((dists ** 2).mean())\n",
    "                tm = compute_tm_score(pred_aligned, true_i, Lref=L)\n",
    "\n",
    "                total_rmsd += rmsd * L\n",
    "                total_tm += tm * L\n",
    "                total_pts += L\n",
    "\n",
    "\n",
    "    mean_rmsd = total_rmsd / total_pts\n",
    "    mean_tm = total_tm / total_pts\n",
    "    model.train()\n",
    "    return mean_rmsd, mean_tm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b092f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train_model(model, dataloader, device, val_loader=None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "    scheduler = CyclicLR(optimizer, base_lr=1e-5, max_lr=1e-3, step_size_up=100, mode='triangular') if config.use_scheduler else None\n",
    "\n",
    "    best_val = float('inf')\n",
    "    loss_fn = nn.SmoothL1Loss(reduction='none')\n",
    "    epoch_losses = []\n",
    "    val_scores = []\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_points = 0\n",
    "        \n",
    "        for seqs, coords, lengths, _, features in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "            seqs = seqs.to(device)\n",
    "            coords = coords.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            features = features.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred_coords = model(seqs, lengths, noise_std=0.2,features=features)\n",
    "            per_nt_loss = loss_fn(pred_coords, coords).sum(-1)\n",
    "            mask = (seqs != config.pad_idx)\n",
    "            loss = (per_nt_loss * mask).sum() / mask.sum().clamp(min=1)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * mask.sum().item()\n",
    "            total_points += mask.sum().item()\n",
    "            global_step += 1\n",
    "        epoch_loss = running_loss / total_points\n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        # Print loss after each epoch\n",
    "        print(f\"\\nEpoch {epoch+1} Loss: {epoch_loss:.5f}\")\n",
    "\n",
    "        if val_loader is not None:\n",
    "            val_rmsd, _ = validate(model, val_loader, device)\n",
    "            val_scores.append(val_rmsd)  \n",
    "    \n",
    "            print(f\"Validation RMSD: {val_rmsd:.5f}\")\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            if val_rmsd < best_val:\n",
    "                best_val = val_rmsd\n",
    "                torch.save(model.state_dict(), 'setnet.pt')\n",
    "                val_rmsd, val_tm = validate(model, val_loader, device)\n",
    "                print(f\"New BEST model saved at Epoch {epoch+1} (RMSD: {val_rmsd:.4f})\")\n",
    "                print(f\"\\nFinal TM-score on validation set: {val_tm:.4f}\")\n",
    "                print(f\"Final RMSD on validation set: {val_rmsd:.4f}\")\n",
    "                 \n",
    "    # plot losses and validation scores\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epoch_losses, label='Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    if val_loader is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(val_scores, label='Validation RMSD', color='r')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('RMSD')\n",
    "        plt.title('Validation RMSD Over Epochs')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5626aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model, seq_csv, submission_csv, device, mean, std, num_predictions=5):\n",
    "    seq_df = pd.read_csv(seq_csv)\n",
    "    model.train()\n",
    "    rows = []\n",
    "    mean = mean.cpu().numpy() if isinstance(mean, torch.Tensor) else mean\n",
    "    std = std.cpu().numpy() if isinstance(std, torch.Tensor) else std\n",
    "    for _, row in seq_df.iterrows():\n",
    "        target_id, seq = row['target_id'], row['sequence'].strip()\n",
    "        seq_tensor = torch.LongTensor([nt_to_idx.get(nt, config.pad_idx) for nt in seq]).unsqueeze(0).to(device)\n",
    "        length = torch.tensor([len(seq)], device=device)\n",
    "\n",
    "        all_coords = []\n",
    "        features = compute_features_for_test(seq, target_id, msa_dir=\"rna-folding/MSA\") # or your correct dir\n",
    "        features = torch.tensor(features, dtype=torch.float32).unsqueeze(0).to(device)  # [1, L, 9]\n",
    "\n",
    "        for _ in range(num_predictions):\n",
    "            with torch.no_grad():\n",
    "                coords = model(seq_tensor, length, features, noise_std=0.1)[0][:length.item()].cpu().numpy()\n",
    "                coords = coords * std + mean\n",
    "                all_coords.append(coords)\n",
    "\n",
    "        for i, nt in enumerate(seq):\n",
    "            row_data = {\n",
    "        \"ID\": f\"{target_id}_{i+1}\",\n",
    "        \"resname\": nt,\n",
    "        \"resid\": i+1,\n",
    "            }\n",
    "            for j, coords_pred in enumerate(all_coords, start=1):\n",
    "                row_data[f\"x_{j}\"] = coords_pred[i][0]\n",
    "                row_data[f\"y_{j}\"] = coords_pred[i][1]\n",
    "                row_data[f\"z_{j}\"] = coords_pred[i][2]\n",
    "            rows.append(row_data)\n",
    "\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(submission_csv, index=False)\n",
    "    print(f\"Submission CSV written: {submission_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b18aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad entry removed: 1ZDI_S\n",
      "Bad entry removed: 7MSF_S\n",
      "Bad entry removed: 5MSF_S\n",
      "Bad entry removed: 1FOQ_A\n",
      "Bad entry removed: 1E7K_D\n",
      "Bad entry removed: 1IBM_Y\n",
      "Bad entry removed: 1JWC_A\n",
      "Bad entry removed: 1LS2_B\n",
      "Bad entry removed: 1OSW_A\n",
      "Bad entry removed: 1P6V_B\n",
      "Bad entry removed: 1P6V_D\n",
      "Bad entry removed: 1QZC_C\n",
      "Bad entry removed: 1R2W_C\n",
      "Bad entry removed: 1QZC_B\n",
      "Bad entry removed: 1QZA_B\n",
      "Bad entry removed: 1QZB_B\n",
      "Bad entry removed: 1RY1_E\n",
      "Bad entry removed: 1Y1Y_P\n",
      "Bad entry removed: 1ZC8_Z\n",
      "Bad entry removed: 1ZC8_G\n",
      "Bad entry removed: 1ZC8_J\n",
      "Bad entry removed: 1ZC8_F\n",
      "Bad entry removed: 1ZC8_I\n",
      "Bad entry removed: 1ZC8_H\n",
      "Bad entry removed: 1X18_D\n",
      "Bad entry removed: 1X18_A\n",
      "Bad entry removed: 1X18_B\n",
      "Bad entry removed: 1ZN1_B\n",
      "Bad entry removed: 1YSH_F\n",
      "Bad entry removed: 2A64_A\n",
      "Bad entry removed: 2BQ5_S\n",
      "Bad entry removed: 2BS0_R\n",
      "Bad entry removed: 2BS0_S\n",
      "Bad entry removed: 2B2E_R\n",
      "Bad entry removed: 2B2E_S\n",
      "Bad entry removed: 2AGN_C\n",
      "Bad entry removed: 2AGN_A\n",
      "Bad entry removed: 2IZN_S\n",
      "Bad entry removed: 2IZ8_R\n",
      "Bad entry removed: 2IZ8_S\n",
      "Bad entry removed: 2DER_D\n",
      "Bad entry removed: 2DET_C\n",
      "Bad entry removed: 1ZBH_E\n",
      "Bad entry removed: 2IY3_B\n",
      "Bad entry removed: 2OB7_D\n",
      "Bad entry removed: 2IL9_M\n",
      "Bad entry removed: 2IL9_A\n",
      "Bad entry removed: 2NR0_H\n",
      "Bad entry removed: 2NR0_G\n",
      "Bad entry removed: 2NR0_F\n",
      "Bad entry removed: 2NR0_E\n",
      "Bad entry removed: 2IZM_S\n",
      "Bad entry removed: 2R93_R\n",
      "Bad entry removed: 2OM7_J\n",
      "Bad entry removed: 2R1G_C\n",
      "Bad entry removed: 2R1G_A\n",
      "Bad entry removed: 2R1G_X\n",
      "Bad entry removed: 2R1G_F\n",
      "Bad entry removed: 2R1G_B\n",
      "Bad entry removed: 2R1G_E\n",
      "Bad entry removed: 3EQ3_E\n",
      "Bad entry removed: 3EQ3_Y\n",
      "Bad entry removed: 3EP2_B\n",
      "Bad entry removed: 3EP2_D\n",
      "Bad entry removed: 3EQ4_A\n",
      "Bad entry removed: 3EP2_C\n",
      "Bad entry removed: 3CW1_v\n",
      "Bad entry removed: 3HAY_E\n",
      "Bad entry removed: 3A3A_A\n",
      "Bad entry removed: 3IZD_A\n",
      "Bad entry removed: 3PGW_N\n",
      "Bad entry removed: 3PIP_Y\n",
      "Bad entry removed: 2XXA_F\n",
      "Bad entry removed: 3TUP_T\n",
      "Bad entry removed: 2LC8_A\n",
      "Bad entry removed: 3UZS_C\n",
      "Bad entry removed: 4ILL_C\n",
      "Bad entry removed: 3W1K_F\n",
      "Bad entry removed: 3WC2_Q\n",
      "Bad entry removed: 3WC2_P\n",
      "Bad entry removed: 3WC1_Q\n",
      "Bad entry removed: 4V5Z_BP\n",
      "Bad entry removed: 4V6X_B2\n",
      "Bad entry removed: 4V6W_B2\n",
      "Bad entry removed: 4V6X_A5\n",
      "Bad entry removed: 4V5Z_BA\n",
      "Bad entry removed: 4V5G_BB\n",
      "Bad entry removed: 4V5Z_BH\n",
      "Bad entry removed: 4V5Z_BL\n",
      "Bad entry removed: 4V5Z_BC\n",
      "Bad entry removed: 4V6U_B1\n",
      "Bad entry removed: 4V5Z_BK\n",
      "Bad entry removed: 4V5Z_AH\n",
      "Bad entry removed: 4V6W_A5\n",
      "Bad entry removed: 4V5Z_BU\n",
      "Bad entry removed: 4V5Z_BQ\n",
      "Bad entry removed: 4V5Z_AF\n",
      "Bad entry removed: 4V5Z_BM\n",
      "Bad entry removed: 4QIL_C\n",
      "Bad entry removed: 4OQ9_3\n",
      "Bad entry removed: 2MNC_A\n",
      "Bad entry removed: 3J8G_A\n",
      "Bad entry removed: 4X4S_B\n",
      "Bad entry removed: 4TUC_QY\n",
      "Bad entry removed: 4TUA_XY\n",
      "Bad entry removed: 2N0R_A\n",
      "Bad entry removed: 4ZT9_D\n",
      "Bad entry removed: 4YVI_C\n",
      "Bad entry removed: 4YVJ_C\n",
      "Bad entry removed: 4YVK_C\n",
      "Bad entry removed: 3JB9_C\n",
      "Bad entry removed: 5GAP_U\n",
      "Bad entry removed: 3JD5_A\n",
      "Bad entry removed: 5KK5_B\n",
      "Bad entry removed: 5XBL_B\n",
      "Bad entry removed: 5O7H_A\n",
      "Bad entry removed: 5V6X_C\n",
      "Bad entry removed: 6EVJ_V\n",
      "Bad entry removed: 5Z3G_B\n",
      "Bad entry removed: 5ZAL_C\n",
      "Bad entry removed: 6C66_J\n",
      "Bad entry removed: 6DU5_B\n",
      "Bad entry removed: 6BZ7_QW\n",
      "Bad entry removed: 6CYT_N\n",
      "Bad entry removed: 6MJ0_B\n",
      "Bad entry removed: 6IFO_D\n",
      "Bad entry removed: 6NDK_XY\n",
      "Bad entry removed: 6AEB_E\n",
      "Bad entry removed: 6IV6_G\n",
      "Bad entry removed: 6QW6_5\n",
      "Bad entry removed: 6DTI_X\n",
      "Bad entry removed: 6NM9_G\n",
      "Bad entry removed: 6O0Z_B\n",
      "Bad entry removed: 6O0Y_B\n",
      "Bad entry removed: 6HYU_D\n",
      "Bad entry removed: 6RR7_D\n",
      "Bad entry removed: 6QX3_D\n",
      "Bad entry removed: 6N7R_R\n",
      "Bad entry removed: 6K4S_A\n",
      "Bad entry removed: 6K3Z_A\n",
      "Bad entry removed: 6KUV_V\n",
      "Bad entry removed: 6RFL_U\n",
      "Bad entry removed: 6SY6_D\n",
      "Bad entry removed: 6V5B_D\n",
      "Bad entry removed: 6WPI_C\n",
      "Bad entry removed: 6WB1_C\n",
      "Bad entry removed: 6OPE_XY\n",
      "Bad entry removed: 6OJ2_QY\n",
      "Bad entry removed: 6W62_B\n",
      "Bad entry removed: 6W5C_B\n",
      "Bad entry removed: 6OSI_RB\n",
      "Bad entry removed: 7D1A_A\n",
      "Bad entry removed: 6LTP_H\n",
      "Bad entry removed: 6Y0C_IN1\n",
      "Bad entry removed: 7B9V_5\n",
      "Bad entry removed: 7LMA_B\n",
      "Bad entry removed: 7LMB_B\n",
      "Bad entry removed: 7D8C_B\n",
      "Bad entry removed: 7OBQ_1\n",
      "Bad entry removed: 7M5O_B\n",
      "Bad entry removed: 7LYT_B\n",
      "Bad entry removed: 7LYS_B\n",
      "Bad entry removed: 7ELE_G\n",
      "Bad entry removed: 6WW6_E\n",
      "Bad entry removed: 6WW6_F\n",
      "Bad entry removed: 6WW6_C\n",
      "Bad entry removed: 7SAM_A\n",
      "Bad entry removed: 7M57_cc\n",
      "Bad entry removed: 7M57_ii\n",
      "Bad entry removed: 7M2T_ss\n",
      "Bad entry removed: 7ORM_H\n",
      "Bad entry removed: 7ORI_H\n",
      "Bad entry removed: 7SLP_R\n",
      "Bad entry removed: 7S36_R\n",
      "Bad entry removed: 7S38_R\n",
      "Bad entry removed: 7S3H_R\n",
      "✅ Fixed mean and std saved!\n",
      "Mean: tensor([ 1.8515e-05,  2.6492e-05, -1.2103e-05])\n",
      "Std: tensor([37.5700, 35.4109, 37.2323])\n",
      "Bad entry removed: 1ZDI_S\n",
      "Bad entry removed: 7MSF_S\n",
      "Bad entry removed: 5MSF_S\n",
      "Bad entry removed: 1FOQ_A\n",
      "Bad entry removed: 1E7K_D\n",
      "Bad entry removed: 1IBM_Y\n",
      "Bad entry removed: 1JWC_A\n",
      "Bad entry removed: 1LS2_B\n",
      "Bad entry removed: 1OSW_A\n",
      "Bad entry removed: 1P6V_B\n",
      "Bad entry removed: 1P6V_D\n",
      "Bad entry removed: 1QZC_C\n",
      "Bad entry removed: 1R2W_C\n",
      "Bad entry removed: 1QZC_B\n",
      "Bad entry removed: 1QZA_B\n",
      "Bad entry removed: 1QZB_B\n",
      "Bad entry removed: 1RY1_E\n",
      "Bad entry removed: 1Y1Y_P\n",
      "Bad entry removed: 1ZC8_Z\n",
      "Bad entry removed: 1ZC8_G\n",
      "Bad entry removed: 1ZC8_J\n",
      "Bad entry removed: 1ZC8_F\n",
      "Bad entry removed: 1ZC8_I\n",
      "Bad entry removed: 1ZC8_H\n",
      "Bad entry removed: 1X18_D\n",
      "Bad entry removed: 1X18_A\n",
      "Bad entry removed: 1X18_B\n",
      "Bad entry removed: 1ZN1_B\n",
      "Bad entry removed: 1YSH_F\n",
      "Bad entry removed: 2A64_A\n",
      "Bad entry removed: 2BQ5_S\n",
      "Bad entry removed: 2BS0_R\n",
      "Bad entry removed: 2BS0_S\n",
      "Bad entry removed: 2B2E_R\n",
      "Bad entry removed: 2B2E_S\n",
      "Bad entry removed: 2AGN_C\n",
      "Bad entry removed: 2AGN_A\n",
      "Bad entry removed: 2IZN_S\n",
      "Bad entry removed: 2IZ8_R\n",
      "Bad entry removed: 2IZ8_S\n",
      "Bad entry removed: 2DER_D\n",
      "Bad entry removed: 2DET_C\n",
      "Bad entry removed: 1ZBH_E\n",
      "Bad entry removed: 2IY3_B\n",
      "Bad entry removed: 2OB7_D\n",
      "Bad entry removed: 2IL9_M\n",
      "Bad entry removed: 2IL9_A\n",
      "Bad entry removed: 2NR0_H\n",
      "Bad entry removed: 2NR0_G\n",
      "Bad entry removed: 2NR0_F\n",
      "Bad entry removed: 2NR0_E\n",
      "Bad entry removed: 2IZM_S\n",
      "Bad entry removed: 2R93_R\n",
      "Bad entry removed: 2OM7_J\n",
      "Bad entry removed: 2R1G_C\n",
      "Bad entry removed: 2R1G_A\n",
      "Bad entry removed: 2R1G_X\n",
      "Bad entry removed: 2R1G_F\n",
      "Bad entry removed: 2R1G_B\n",
      "Bad entry removed: 2R1G_E\n",
      "Bad entry removed: 3EQ3_E\n",
      "Bad entry removed: 3EQ3_Y\n",
      "Bad entry removed: 3EP2_B\n",
      "Bad entry removed: 3EP2_D\n",
      "Bad entry removed: 3EQ4_A\n",
      "Bad entry removed: 3EP2_C\n",
      "Bad entry removed: 3CW1_v\n",
      "Bad entry removed: 3HAY_E\n",
      "Bad entry removed: 3A3A_A\n",
      "Bad entry removed: 3IZD_A\n",
      "Bad entry removed: 3PGW_N\n",
      "Bad entry removed: 3PIP_Y\n",
      "Bad entry removed: 2XXA_F\n",
      "Bad entry removed: 3TUP_T\n",
      "Bad entry removed: 2LC8_A\n",
      "Bad entry removed: 3UZS_C\n",
      "Bad entry removed: 4ILL_C\n",
      "Bad entry removed: 3W1K_F\n",
      "Bad entry removed: 3WC2_Q\n",
      "Bad entry removed: 3WC2_P\n",
      "Bad entry removed: 3WC1_Q\n",
      "Bad entry removed: 4V5Z_BP\n",
      "Bad entry removed: 4V6X_B2\n",
      "Bad entry removed: 4V6W_B2\n",
      "Bad entry removed: 4V6X_A5\n",
      "Bad entry removed: 4V5Z_BA\n",
      "Bad entry removed: 4V5G_BB\n",
      "Bad entry removed: 4V5Z_BH\n",
      "Bad entry removed: 4V5Z_BL\n",
      "Bad entry removed: 4V5Z_BC\n",
      "Bad entry removed: 4V6U_B1\n",
      "Bad entry removed: 4V5Z_BK\n",
      "Bad entry removed: 4V5Z_AH\n",
      "Bad entry removed: 4V6W_A5\n",
      "Bad entry removed: 4V5Z_BU\n",
      "Bad entry removed: 4V5Z_BQ\n",
      "Bad entry removed: 4V5Z_AF\n",
      "Bad entry removed: 4V5Z_BM\n",
      "Bad entry removed: 4QIL_C\n",
      "Bad entry removed: 4OQ9_3\n",
      "Bad entry removed: 2MNC_A\n",
      "Bad entry removed: 3J8G_A\n",
      "Bad entry removed: 4X4S_B\n",
      "Bad entry removed: 4TUC_QY\n",
      "Bad entry removed: 4TUA_XY\n",
      "Bad entry removed: 2N0R_A\n",
      "Bad entry removed: 4ZT9_D\n",
      "Bad entry removed: 4YVI_C\n",
      "Bad entry removed: 4YVJ_C\n",
      "Bad entry removed: 4YVK_C\n",
      "Bad entry removed: 3JB9_C\n",
      "Bad entry removed: 5GAP_U\n",
      "Bad entry removed: 3JD5_A\n",
      "Bad entry removed: 5KK5_B\n",
      "Bad entry removed: 5XBL_B\n",
      "Bad entry removed: 5O7H_A\n",
      "Bad entry removed: 5V6X_C\n",
      "Bad entry removed: 6EVJ_V\n",
      "Bad entry removed: 5Z3G_B\n",
      "Bad entry removed: 5ZAL_C\n",
      "Bad entry removed: 6C66_J\n",
      "Bad entry removed: 6DU5_B\n",
      "Bad entry removed: 6BZ7_QW\n",
      "Bad entry removed: 6CYT_N\n",
      "Bad entry removed: 6MJ0_B\n",
      "Bad entry removed: 6IFO_D\n",
      "Bad entry removed: 6NDK_XY\n",
      "Bad entry removed: 6AEB_E\n",
      "Bad entry removed: 6IV6_G\n",
      "Bad entry removed: 6QW6_5\n",
      "Bad entry removed: 6DTI_X\n",
      "Bad entry removed: 6NM9_G\n",
      "Bad entry removed: 6O0Z_B\n",
      "Bad entry removed: 6O0Y_B\n",
      "Bad entry removed: 6HYU_D\n",
      "Bad entry removed: 6RR7_D\n",
      "Bad entry removed: 6QX3_D\n",
      "Bad entry removed: 6N7R_R\n",
      "Bad entry removed: 6K4S_A\n",
      "Bad entry removed: 6K3Z_A\n",
      "Bad entry removed: 6KUV_V\n",
      "Bad entry removed: 6RFL_U\n",
      "Bad entry removed: 6SY6_D\n",
      "Bad entry removed: 6V5B_D\n",
      "Bad entry removed: 6WPI_C\n",
      "Bad entry removed: 6WB1_C\n",
      "Bad entry removed: 6OPE_XY\n",
      "Bad entry removed: 6OJ2_QY\n",
      "Bad entry removed: 6W62_B\n",
      "Bad entry removed: 6W5C_B\n",
      "Bad entry removed: 6OSI_RB\n",
      "Bad entry removed: 7D1A_A\n",
      "Bad entry removed: 6LTP_H\n",
      "Bad entry removed: 6Y0C_IN1\n",
      "Bad entry removed: 7B9V_5\n",
      "Bad entry removed: 7LMA_B\n",
      "Bad entry removed: 7LMB_B\n",
      "Bad entry removed: 7D8C_B\n",
      "Bad entry removed: 7OBQ_1\n",
      "Bad entry removed: 7M5O_B\n",
      "Bad entry removed: 7LYT_B\n",
      "Bad entry removed: 7LYS_B\n",
      "Bad entry removed: 7ELE_G\n",
      "Bad entry removed: 6WW6_E\n",
      "Bad entry removed: 6WW6_F\n",
      "Bad entry removed: 6WW6_C\n",
      "Bad entry removed: 7SAM_A\n",
      "Bad entry removed: 7M57_cc\n",
      "Bad entry removed: 7M57_ii\n",
      "Bad entry removed: 7M2T_ss\n",
      "Bad entry removed: 7ORM_H\n",
      "Bad entry removed: 7ORI_H\n",
      "Bad entry removed: 7SLP_R\n",
      "Bad entry removed: 7S36_R\n",
      "Bad entry removed: 7S38_R\n",
      "Bad entry removed: 7S3H_R\n",
      "Bad entry removed: 1ZDI_S\n",
      "Bad entry removed: 7MSF_S\n",
      "Bad entry removed: 5MSF_S\n",
      "Bad entry removed: 1FOQ_A\n",
      "Bad entry removed: 1E7K_D\n",
      "Bad entry removed: 1IBM_Y\n",
      "Bad entry removed: 1JWC_A\n",
      "Bad entry removed: 1LS2_B\n",
      "Bad entry removed: 1OSW_A\n",
      "Bad entry removed: 1P6V_B\n",
      "Bad entry removed: 1P6V_D\n",
      "Bad entry removed: 1QZC_C\n",
      "Bad entry removed: 1R2W_C\n",
      "Bad entry removed: 1QZC_B\n",
      "Bad entry removed: 1QZA_B\n",
      "Bad entry removed: 1QZB_B\n",
      "Bad entry removed: 1RY1_E\n",
      "Bad entry removed: 1Y1Y_P\n",
      "Bad entry removed: 1ZC8_Z\n",
      "Bad entry removed: 1ZC8_G\n",
      "Bad entry removed: 1ZC8_J\n",
      "Bad entry removed: 1ZC8_F\n",
      "Bad entry removed: 1ZC8_I\n",
      "Bad entry removed: 1ZC8_H\n",
      "Bad entry removed: 1X18_D\n",
      "Bad entry removed: 1X18_A\n",
      "Bad entry removed: 1X18_B\n",
      "Bad entry removed: 1ZN1_B\n",
      "Bad entry removed: 1YSH_F\n",
      "Bad entry removed: 2A64_A\n",
      "Bad entry removed: 2BQ5_S\n",
      "Bad entry removed: 2BS0_R\n",
      "Bad entry removed: 2BS0_S\n",
      "Bad entry removed: 2B2E_R\n",
      "Bad entry removed: 2B2E_S\n",
      "Bad entry removed: 2AGN_C\n",
      "Bad entry removed: 2AGN_A\n",
      "Bad entry removed: 2IZN_S\n",
      "Bad entry removed: 2IZ8_R\n",
      "Bad entry removed: 2IZ8_S\n",
      "Bad entry removed: 2DER_D\n",
      "Bad entry removed: 2DET_C\n",
      "Bad entry removed: 1ZBH_E\n",
      "Bad entry removed: 2IY3_B\n",
      "Bad entry removed: 2OB7_D\n",
      "Bad entry removed: 2IL9_M\n",
      "Bad entry removed: 2IL9_A\n",
      "Bad entry removed: 2NR0_H\n",
      "Bad entry removed: 2NR0_G\n",
      "Bad entry removed: 2NR0_F\n",
      "Bad entry removed: 2NR0_E\n",
      "Bad entry removed: 2IZM_S\n",
      "Bad entry removed: 2R93_R\n",
      "Bad entry removed: 2OM7_J\n",
      "Bad entry removed: 2R1G_C\n",
      "Bad entry removed: 2R1G_A\n",
      "Bad entry removed: 2R1G_X\n",
      "Bad entry removed: 2R1G_F\n",
      "Bad entry removed: 2R1G_B\n",
      "Bad entry removed: 2R1G_E\n",
      "Bad entry removed: 3EQ3_E\n",
      "Bad entry removed: 3EQ3_Y\n",
      "Bad entry removed: 3EP2_B\n",
      "Bad entry removed: 3EP2_D\n",
      "Bad entry removed: 3EQ4_A\n",
      "Bad entry removed: 3EP2_C\n",
      "Bad entry removed: 3CW1_v\n",
      "Bad entry removed: 3HAY_E\n",
      "Bad entry removed: 3A3A_A\n",
      "Bad entry removed: 3IZD_A\n",
      "Bad entry removed: 3PGW_N\n",
      "Bad entry removed: 3PIP_Y\n",
      "Bad entry removed: 2XXA_F\n",
      "Bad entry removed: 3TUP_T\n",
      "Bad entry removed: 2LC8_A\n",
      "Bad entry removed: 3UZS_C\n",
      "Bad entry removed: 4ILL_C\n",
      "Bad entry removed: 3W1K_F\n",
      "Bad entry removed: 3WC2_Q\n",
      "Bad entry removed: 3WC2_P\n",
      "Bad entry removed: 3WC1_Q\n",
      "Bad entry removed: 4V5Z_BP\n",
      "Bad entry removed: 4V6X_B2\n",
      "Bad entry removed: 4V6W_B2\n",
      "Bad entry removed: 4V6X_A5\n",
      "Bad entry removed: 4V5Z_BA\n",
      "Bad entry removed: 4V5G_BB\n",
      "Bad entry removed: 4V5Z_BH\n",
      "Bad entry removed: 4V5Z_BL\n",
      "Bad entry removed: 4V5Z_BC\n",
      "Bad entry removed: 4V6U_B1\n",
      "Bad entry removed: 4V5Z_BK\n",
      "Bad entry removed: 4V5Z_AH\n",
      "Bad entry removed: 4V6W_A5\n",
      "Bad entry removed: 4V5Z_BU\n",
      "Bad entry removed: 4V5Z_BQ\n",
      "Bad entry removed: 4V5Z_AF\n",
      "Bad entry removed: 4V5Z_BM\n",
      "Bad entry removed: 4QIL_C\n",
      "Bad entry removed: 4OQ9_3\n",
      "Bad entry removed: 2MNC_A\n",
      "Bad entry removed: 3J8G_A\n",
      "Bad entry removed: 4X4S_B\n",
      "Bad entry removed: 4TUC_QY\n",
      "Bad entry removed: 4TUA_XY\n",
      "Bad entry removed: 2N0R_A\n",
      "Bad entry removed: 4ZT9_D\n",
      "Bad entry removed: 4YVI_C\n",
      "Bad entry removed: 4YVJ_C\n",
      "Bad entry removed: 4YVK_C\n",
      "Bad entry removed: 3JB9_C\n",
      "Bad entry removed: 5GAP_U\n",
      "Bad entry removed: 3JD5_A\n",
      "Bad entry removed: 5KK5_B\n",
      "Bad entry removed: 5XBL_B\n",
      "Bad entry removed: 5O7H_A\n",
      "Bad entry removed: 5V6X_C\n",
      "Bad entry removed: 6EVJ_V\n",
      "Bad entry removed: 5Z3G_B\n",
      "Bad entry removed: 5ZAL_C\n",
      "Bad entry removed: 6C66_J\n",
      "Bad entry removed: 6DU5_B\n",
      "Bad entry removed: 6BZ7_QW\n",
      "Bad entry removed: 6CYT_N\n",
      "Bad entry removed: 6MJ0_B\n",
      "Bad entry removed: 6IFO_D\n",
      "Bad entry removed: 6NDK_XY\n",
      "Bad entry removed: 6AEB_E\n",
      "Bad entry removed: 6IV6_G\n",
      "Bad entry removed: 6QW6_5\n",
      "Bad entry removed: 6DTI_X\n",
      "Bad entry removed: 6NM9_G\n",
      "Bad entry removed: 6O0Z_B\n",
      "Bad entry removed: 6O0Y_B\n",
      "Bad entry removed: 6HYU_D\n",
      "Bad entry removed: 6RR7_D\n",
      "Bad entry removed: 6QX3_D\n",
      "Bad entry removed: 6N7R_R\n",
      "Bad entry removed: 6K4S_A\n",
      "Bad entry removed: 6K3Z_A\n",
      "Bad entry removed: 6KUV_V\n",
      "Bad entry removed: 6RFL_U\n",
      "Bad entry removed: 6SY6_D\n",
      "Bad entry removed: 6V5B_D\n",
      "Bad entry removed: 6WPI_C\n",
      "Bad entry removed: 6WB1_C\n",
      "Bad entry removed: 6OPE_XY\n",
      "Bad entry removed: 6OJ2_QY\n",
      "Bad entry removed: 6W62_B\n",
      "Bad entry removed: 6W5C_B\n",
      "Bad entry removed: 6OSI_RB\n",
      "Bad entry removed: 7D1A_A\n",
      "Bad entry removed: 6LTP_H\n",
      "Bad entry removed: 6Y0C_IN1\n",
      "Bad entry removed: 7B9V_5\n",
      "Bad entry removed: 7LMA_B\n",
      "Bad entry removed: 7LMB_B\n",
      "Bad entry removed: 7D8C_B\n",
      "Bad entry removed: 7OBQ_1\n",
      "Bad entry removed: 7M5O_B\n",
      "Bad entry removed: 7LYT_B\n",
      "Bad entry removed: 7LYS_B\n",
      "Bad entry removed: 7ELE_G\n",
      "Bad entry removed: 6WW6_E\n",
      "Bad entry removed: 6WW6_F\n",
      "Bad entry removed: 6WW6_C\n",
      "Bad entry removed: 7SAM_A\n",
      "Bad entry removed: 7M57_cc\n",
      "Bad entry removed: 7M57_ii\n",
      "Bad entry removed: 7M2T_ss\n",
      "Bad entry removed: 7ORM_H\n",
      "Bad entry removed: 7ORI_H\n",
      "Bad entry removed: 7SLP_R\n",
      "Bad entry removed: 7S36_R\n",
      "Bad entry removed: 7S38_R\n",
      "Bad entry removed: 7S3H_R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pradip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|██████████| 110/110 [00:37<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Loss: 7.08808\n",
      "Validation RMSD: 6.61341\n",
      "New BEST model saved at Epoch 1 (RMSD: 6.6134)\n",
      "\n",
      "Final TM-score on validation set: 0.6842\n",
      "Final RMSD on validation set: 6.6134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 110/110 [00:38<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Loss: 6.77096\n",
      "Validation RMSD: 6.61113\n",
      "New BEST model saved at Epoch 2 (RMSD: 6.6111)\n",
      "\n",
      "Final TM-score on validation set: 0.6841\n",
      "Final RMSD on validation set: 6.6111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 110/110 [00:38<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Loss: 6.70010\n",
      "Validation RMSD: 6.60866\n",
      "New BEST model saved at Epoch 3 (RMSD: 6.6087)\n",
      "\n",
      "Final TM-score on validation set: 0.6842\n",
      "Final RMSD on validation set: 6.6087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  10%|█         | 11/110 [00:06<00:57,  1.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mrna_collate)\n\u001b[0;32m     55\u001b[0m model \u001b[38;5;241m=\u001b[39m RNA3DNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 56\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m stats \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_std.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m mean, std \u001b[38;5;241m=\u001b[39m stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m], stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[174], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, device, val_loader)\u001b[0m\n\u001b[0;32m     36\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 38\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m mask\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     39\u001b[0m total_points \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     40\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "full_dataset = RNAStruct(\n",
    "    \"rna-folding/train_sequences.cutoff_filtered.csv\",\n",
    "    \"rna-folding/train_labels.cutoff_filtered.csv\"\n",
    ")\n",
    "\n",
    "all_ids = [target_id for target_id, _, _, _ in full_dataset.samples]\n",
    "id_to_idx = {t: i for i, (t, _, _, _) in enumerate(full_dataset.samples)}\n",
    "train_ids, val_ids = train_test_split(all_ids, test_size=0.15, random_state=config.seed)\n",
    "\n",
    "train_indices = [id_to_idx[t] for t in train_ids if t in id_to_idx]\n",
    "val_indices   = [id_to_idx[t] for t in val_ids if t in id_to_idx]\n",
    "\n",
    "valid_coords = []\n",
    "\n",
    "for i in train_indices:\n",
    "    target_id, seq_idx, coords, features = full_dataset.samples[i]\n",
    "    if coords.shape[0] == len(seq_idx) and np.all(np.isfinite(coords)):\n",
    "        centered = coords - coords.mean(axis=0)\n",
    "        valid_coords.append(centered)\n",
    "\n",
    "\n",
    "# Combine and compute\n",
    "all_coords = np.concatenate(valid_coords, axis=0)\n",
    "mean = torch.tensor(all_coords.mean(axis=0), dtype=torch.float32)\n",
    "std = torch.tensor(all_coords.std(axis=0), dtype=torch.float32)\n",
    "\n",
    "# Save\n",
    "torch.save({'mean': mean, 'std': std}, 'mean_std.pt')\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)\n",
    "\n",
    "\n",
    "train_dataset = RNAStruct(\n",
    "    \"rna-folding/train_sequences.cutoff_filtered.csv\",\n",
    "    \"rna-folding/train_labels.cutoff_filtered.csv\",\n",
    "    mean=mean,\n",
    "    std=std\n",
    ")\n",
    "val_dataset = RNAStruct(\n",
    "    \"rna-folding/train_sequences.cutoff_filtered.csv\",\n",
    "    \"rna-folding/train_labels.cutoff_filtered.csv\",\n",
    "    mean=mean,\n",
    "    std=std\n",
    ")\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_indices)\n",
    "val_dataset = Subset(val_dataset, val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=rna_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=rna_collate)\n",
    "\n",
    "model = RNA3DNet().to(device)\n",
    "train_model(model, train_loader, device, val_loader=val_loader)\n",
    "\n",
    "stats = torch.load('mean_std.pt')\n",
    "mean, std = stats['mean'], stats['std']\n",
    "\n",
    "mean = mean.numpy() if isinstance(mean, torch.Tensor) else mean\n",
    "std = std.numpy() if isinstance(std, torch.Tensor) else std\n",
    "\n",
    "print(\"🚨 Final sanity check:\")\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)\n",
    "\n",
    "\n",
    "submission(\n",
    "    model,\n",
    "    \"rna-folding/test_sequences.csv\",\n",
    "    \"rna-folding/submission.csv\",\n",
    "    device,\n",
    "    mean,\n",
    "    std\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
