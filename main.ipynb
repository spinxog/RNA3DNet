{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42561c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "nt_to_idx = {'A': 0, 'U': 1, 'G': 2, 'C': 3, 'N': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c6b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    vocab_size = len(nt_to_idx)\n",
    "    max_len = 512\n",
    "    emb_dim = 128\n",
    "    num_layers = 6\n",
    "    nhead = 4\n",
    "    ff_dim = 512\n",
    "    dropout = 0.4\n",
    "    batch_size = 2\n",
    "    epochs = 30\n",
    "    lr = 5e-3\n",
    "    pad_idx = 4\n",
    "    \n",
    "    use_scheduler = True\n",
    "    seed = 42\n",
    "\n",
    "    def set_seed(self):\n",
    "        torch.manual_seed(self.seed)\n",
    "        torch.cuda.manual_seed_all(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        random.seed(self.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "config = Config()\n",
    "config.set_seed()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\"cpu\")\n",
    "torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ed86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNAStruct(Dataset):\n",
    "    def __init__(self, seq_csv, labels_csv, mean=None, std=None, normalize=True):\n",
    "        seq_df = pd.read_csv(seq_csv)\n",
    "        seq_map = {row['target_id']: row['sequence'].strip() for _, row in seq_df.iterrows()}\n",
    "\n",
    "        labels_df = pd.read_csv(labels_csv)\n",
    "        self.data = {}\n",
    "        for _, row in labels_df.iterrows():\n",
    "            target_id = row['ID'].rsplit('_', 1)[0]\n",
    "            idx = int(row['resid']) - 1\n",
    "            if target_id not in self.data:\n",
    "                self.data[target_id] = []\n",
    "            self.data[target_id].append((idx, row['resname'], row['x_1'], row['y_1'], row['z_1']))\n",
    "\n",
    "        self.samples = []\n",
    "        for target_id in self.data:\n",
    "            dat = sorted(self.data[target_id], key=lambda x: x[0])\n",
    "            seq = seq_map[target_id]\n",
    "            coords = np.array([[x[2], x[3], x[4]] for x in dat], dtype=np.float32)\n",
    "            if len(seq) == len(coords) and np.isfinite(coords).all():\n",
    "                seq_idx = np.array([nt_to_idx.get(nt, 4) for nt in seq], dtype=np.int64)\n",
    "                self.samples.append((target_id, seq_idx, coords))\n",
    "            else:\n",
    "                print(f\"Bad entry removed: {target_id} (len/coords/finite)\")\n",
    "\n",
    "        all_coords = np.concatenate([coords for _, _, coords in self.samples], axis=0)\n",
    "        self.mean = mean if mean is not None else all_coords.mean(axis=0)\n",
    "        self.std = std if std is not None else all_coords.std(axis=0)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target_id, seq_idx, coords = self.samples[idx]\n",
    "        length = len(seq_idx)\n",
    "        if self.normalize:\n",
    "            if isinstance(self.mean, torch.Tensor):\n",
    "                mean = self.mean.numpy()\n",
    "            else:\n",
    "                mean = self.mean\n",
    "            if isinstance(self.std, torch.Tensor):\n",
    "                std = self.std.numpy()\n",
    "            else:\n",
    "                std = self.std\n",
    "            norm_coords = (coords - mean) / std\n",
    "            return (\n",
    "        torch.LongTensor(seq_idx),\n",
    "        torch.tensor(norm_coords, dtype=torch.float32),\n",
    "        length,\n",
    "        target_id\n",
    "    ) \n",
    "    def get_mean_std(self,):\n",
    "        return self.mean, self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63039fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        device = x.device\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, self.d_model, 2, device=device).float() * (-math.log(10000.0) / self.d_model)\n",
    "        )\n",
    "        pe = torch.zeros(seq_len, self.d_model, device=device)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return x + pe.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdff36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate function\n",
    "def rna_collate(batch):\n",
    "    seqs, coords, lengths, target_ids = zip(*batch)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    seqs_padded = pad_sequence(seqs, batch_first=True, padding_value=4)\n",
    "    coords_padded = pad_sequence(coords, batch_first=True, padding_value=0)\n",
    "    return seqs_padded, coords_padded, lengths, target_ids\n",
    "\n",
    "\n",
    "# Model\n",
    "class RNA3DNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(config.vocab_size, config.emb_dim, padding_idx=config.pad_idx)\n",
    "        self.pos_enc = PositionalEncoding(config.emb_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config.emb_dim, nhead=config.nhead, dim_feedforward=config.ff_dim,\n",
    "            dropout=config.dropout, batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config.num_layers)\n",
    "        self.ln = nn.LayerNorm(config.emb_dim)\n",
    "        self.fc = nn.Sequential(nn.Dropout(config.dropout), nn.Linear(config.emb_dim, 3)) \n",
    "    def forward(self, seq, lengths, noise_std=0.0):\n",
    "        x = self.embed(seq)\n",
    "        if noise_std > 0:\n",
    "            noise = torch.randn_like(x) * noise_std\n",
    "            x = x + noise\n",
    "        x = self.pos_enc(x)\n",
    "        mask = (seq == 4) \n",
    "        x = self.encoder(x, src_key_padding_mask=mask)\n",
    "        x = self.ln(x)\n",
    "        coords = self.fc(x)\n",
    "        return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tm_score(pred_coords, true_coords, Lref=None):\n",
    "    assert pred_coords.shape == true_coords.shape\n",
    "    L = pred_coords.shape[0]\n",
    "    Lref = Lref if Lref is not None else L\n",
    "    dists = np.linalg.norm(pred_coords - true_coords, axis=1)\n",
    "    \n",
    "    # d0 depends on Lref\n",
    "    if Lref >= 30:\n",
    "        d0 = 1.24 * (Lref - 15) ** (1/3) - 1.8\n",
    "    elif Lref >= 24:\n",
    "        d0 = 0.7\n",
    "    elif Lref >= 20:\n",
    "        d0 = 0.6\n",
    "    elif Lref >= 16:\n",
    "        d0 = 0.5\n",
    "    elif Lref >= 12:\n",
    "        d0 = 0.4\n",
    "    else:\n",
    "        d0 = 0.3\n",
    "\n",
    "    score = (1 / Lref) * np.sum(1 / (1 + (dists / d0) ** 2))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e373f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kabsch_align(P, Q):\n",
    "    C = np.dot(P.T, Q)\n",
    "    V, S, Wt = np.linalg.svd(C)\n",
    "    d = (np.linalg.det(V) * np.linalg.det(Wt)) < 0.0\n",
    "    if d:\n",
    "        V[:, -1] = -V[:, -1]\n",
    "    U = np.dot(V, Wt)\n",
    "    return np.dot(P, U)\n",
    "\n",
    "\n",
    "\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_pts, total_rmsd, total_tm = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for seqs, coords, lengths, _ in dataloader:\n",
    "            seqs, coords, lengths = seqs.to(device), coords.to(device), lengths.to(device)\n",
    "            pred_coords = model(seqs, lengths)\n",
    "            for i in range(seqs.size(0)):\n",
    "                L = lengths[i].item()\n",
    "                pred = pred_coords[i, :L].cpu().numpy()\n",
    "                true = coords[i, :L].cpu().numpy()\n",
    "\n",
    "                pred_centered = pred - pred.mean(axis=0)\n",
    "                true_centered = true - true.mean(axis=0)\n",
    "                aligned_pred = kabsch_align(pred_centered, true_centered)\n",
    "                dists = np.linalg.norm(aligned_pred - true_centered, axis=1)\n",
    "                rmsd = np.sqrt((dists ** 2).mean())\n",
    "                tm = compute_tm_score(aligned_pred, true_centered, Lref=L)\n",
    "\n",
    "                total_rmsd += rmsd * L\n",
    "                total_tm += tm * L\n",
    "                total_pts += L\n",
    "\n",
    "    mean_rmsd = total_rmsd / total_pts\n",
    "    mean_tm = total_tm / total_pts\n",
    "    model.train()\n",
    "    return mean_rmsd, mean_tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train_model(model, dataloader, device, val_loader=None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr) #adamW\n",
    "    num_training_steps = config.epochs * len(dataloader)\n",
    "    num_warmup_steps = int(0.1 * num_training_steps)\n",
    "    #CosineAnnealingLR(optimizer, T_max=100) #ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=num_warmup_steps,num_training_steps=num_training_steps)if config.use_scheduler else None\n",
    "    #loss_fn = nn.MSELoss(reduction='none')\n",
    "    best_val = float('inf')\n",
    "\n",
    "    epoch_losses = []\n",
    "    val_scores = []\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_points = 0\n",
    "        \n",
    "        for seqs, coords, lengths, _ in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "            seqs, coords, lengths = seqs.to(device), coords.to(device), lengths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred_coords = model(seqs, lengths)\n",
    "            mse_per_nt = ((pred_coords - coords) ** 2).sum(-1)    \n",
    "            mask = (seqs != config.pad_idx)\n",
    "            loss = (mse_per_nt * mask).sum() / mask.sum().clamp(min=1)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * mask.sum().item()\n",
    "            total_points += mask.sum().item()\n",
    "            global_step += 1\n",
    "        epoch_loss = running_loss / total_points\n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        # Print loss after each epoch\n",
    "        print(f\"\\nEpoch {epoch+1} Loss: {epoch_loss:.5f}\")\n",
    "\n",
    "        if val_loader is not None:\n",
    "            val_rmsd, _ = validate(model, val_loader, device)\n",
    "            val_scores.append(val_rmsd)  \n",
    "    \n",
    "            print(f\"Validation RMSD: {val_rmsd:.5f}\")\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            if val_rmsd < best_val:\n",
    "                best_val = val_rmsd\n",
    "                torch.save(model.state_dict(), 'setnet.pt')\n",
    "                val_rmsd, val_tm = validate(model, val_loader, device)\n",
    "                print(f\"New BEST model saved at Epoch {epoch+1} (RMSD: {val_rmsd:.4f})\")\n",
    "                print(f\"\\nFinal TM-score on validation set: {val_tm:.4f}\")\n",
    "                print(f\"Final RMSD on validation set: {val_rmsd:.4f}\")\n",
    "                 \n",
    "    # plot losses and validation scores\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epoch_losses, label='Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    if val_loader is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(val_scores, label='Validation RMSD', color='r')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('RMSD')\n",
    "        plt.title('Validation RMSD Over Epochs')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c62a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_dropout(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.train()\n",
    "\n",
    "def submission(model, seq_csv, submission_csv, device, mean, std, num_predictions=5):\n",
    "    seq_df = pd.read_csv(seq_csv)\n",
    "    model.eval()\n",
    "    enable_dropout(model)\n",
    "    rows = []\n",
    "\n",
    "    for _, row in seq_df.iterrows():\n",
    "        target_id, seq = row['target_id'], row['sequence'].strip()\n",
    "        seq_tensor = torch.LongTensor([nt_to_idx.get(nt, config.pad_idx) for nt in seq]).unsqueeze(0).to(device)\n",
    "        length = torch.tensor([len(seq)], device=device)\n",
    "\n",
    "        all_coords = []\n",
    "\n",
    "        for _ in range(num_predictions):\n",
    "            with torch.no_grad():\n",
    "                coords = model(seq_tensor, length, noise_std=0.1)[0][:length.item()].cpu().numpy()\n",
    "                coords = coords * std + mean\n",
    "                all_coords.append(coords)\n",
    "\n",
    "        for i, nt in enumerate(seq):\n",
    "            row_data = {\n",
    "                \"ID\": f\"{target_id}_{i+1}\",\n",
    "                \"resname\": nt,\n",
    "                \"resid\": i+1,\n",
    "            }\n",
    "            for j in range(num_predictions):\n",
    "                row_data[f\"x_{j+1}\"] = all_coords[j][i][0]\n",
    "                row_data[f\"y_{j+1}\"] = all_coords[j][i][1]\n",
    "                row_data[f\"z_{j+1}\"] = all_coords[j][i][2]\n",
    "\n",
    "            rows.append(row_data)\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(submission_csv, index=False)\n",
    "    print(f\"Submission CSV written: {submission_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "with open(\"split_indices_ids.pkl\", \"rb\") as f:\n",
    "    split = pickle.load(f)\n",
    "train_ids = split['train_ids']\n",
    "val_ids   = split['val_ids']\n",
    "\n",
    "full_dataset = RNAStruct(\"rna-folding/train_sequences_clean.v2.csv\", \"rna-folding/train_labels_clean.v2.csv\")\n",
    "\n",
    "id_to_idx = {t: i for i, (t, _, _) in enumerate(full_dataset.samples)}\n",
    "\n",
    "train_indices = [id_to_idx[t] for t in train_ids if t in id_to_idx]\n",
    "val_indices   = [id_to_idx[t] for t in val_ids if t in id_to_idx]\n",
    "\n",
    "all_train_coords = [full_dataset.samples[i][2] for i in train_indices]\n",
    "all_train_coords = np.concatenate(all_train_coords, axis=0)\n",
    "mean = torch.tensor(all_train_coords.mean(axis=0), dtype=torch.float32)\n",
    "std = torch.tensor(all_train_coords.std(axis=0), dtype=torch.float32)\n",
    "torch.save({'mean': mean, 'std': std}, 'mean_std.pt')\n",
    "\n",
    "\n",
    "train_dataset = RNAStruct(\n",
    "    \"rna-folding/train_sequences_clean.v2.csv\",\n",
    "    \"rna-folding/train_labels_clean.v2.csv\",\n",
    "    mean=mean, std=std\n",
    ")\n",
    "val_dataset = RNAStruct(\n",
    "    \"rna-folding/train_sequences_clean.v2.csv\",\n",
    "    \"rna-folding/train_labels_clean.v2.csv\",\n",
    "    mean=mean, std=std\n",
    ")\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_indices)\n",
    "val_dataset = Subset(val_dataset, val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=rna_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=rna_collate)\n",
    "\n",
    "model = RNA3DNet().to(device)\n",
    "train_model(model, train_loader, device, val_loader=val_loader)\n",
    "\n",
    "stats = torch.load('mean_std.pt')\n",
    "mean, std = stats['mean'], stats['std']\n",
    "model.load_state_dict(torch.load('setnet.pt'))\n",
    "submission(\n",
    "    model,\n",
    "    \"rna-folding/test_sequences.csv\",\n",
    "    \"rna-folding/submission.csv\",\n",
    "    device,\n",
    "    mean, std\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
