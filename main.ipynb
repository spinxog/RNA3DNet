{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42561c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from ndlinear import NdLinear\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "nt_to_idx = {'A': 0, 'U': 1, 'G': 2, 'C': 3, 'N': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ed86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNAStruct(Dataset):\n",
    "    def __init__(self, seq_csv, labels_csv, mean=None, std=None, normalize=True):\n",
    "        seq_df = pd.read_csv(seq_csv)\n",
    "        seq_map = {row['target_id']: row['sequence'].strip() for _, row in seq_df.iterrows()}\n",
    "\n",
    "        labels_df = pd.read_csv(labels_csv)\n",
    "        self.data = {}\n",
    "        for _, row in labels_df.iterrows():\n",
    "            target_id = row['ID'].rsplit('_', 1)[0]\n",
    "            idx = int(row['resid']) - 1\n",
    "            if target_id not in self.data:\n",
    "                self.data[target_id] = []\n",
    "            self.data[target_id].append((idx, row['resname'], row['x_1'], row['y_1'], row['z_1']))\n",
    "\n",
    "        self.samples = []\n",
    "        for target_id in self.data:\n",
    "            dat = sorted(self.data[target_id], key=lambda x: x[0])\n",
    "            seq = seq_map[target_id]\n",
    "            coords = np.array([[x[2], x[3], x[4]] for x in dat], dtype=np.float32)\n",
    "            if len(seq) == len(coords) and np.isfinite(coords).all():\n",
    "                seq_idx = np.array([nt_to_idx.get(nt, 4) for nt in seq], dtype=np.int64)\n",
    "                self.samples.append((target_id, seq_idx, coords))\n",
    "            else:\n",
    "                print(f\"Bad entry removed: {target_id} (len/coords/finite)\")\n",
    "\n",
    "        all_coords = np.concatenate([coords for _, _, coords in self.samples], axis=0)\n",
    "        self.mean = mean if mean is not None else all_coords.mean(axis=0)\n",
    "        self.std = std if std is not None else all_coords.std(axis=0)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target_id, seq_idx, coords = self.samples[idx]\n",
    "        length = len(seq_idx)\n",
    "        if self.normalize:\n",
    "            norm_coords = (coords - self.mean) / self.std\n",
    "            return (\n",
    "                torch.LongTensor(seq_idx),\n",
    "                torch.tensor(norm_coords, dtype=torch.float32),\n",
    "                length,\n",
    "                target_id\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                torch.LongTensor(seq_idx),\n",
    "                torch.tensor(coords, dtype=torch.float32),\n",
    "                length,\n",
    "                target_id\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fdff36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate function\n",
    "def rna_collate(batch):\n",
    "    seqs, coords, lengths, target_ids = zip(*batch)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    seqs_padded = pad_sequence(seqs, batch_first=True, padding_value=4)\n",
    "    coords_padded = pad_sequence(coords, batch_first=True, padding_value=0)\n",
    "    return seqs_padded, coords_padded, lengths, target_ids\n",
    "\n",
    "\n",
    "# Model\n",
    "class RNA3DNet(nn.Module):\n",
    "    def __init__(self, vocab_size=5, emb_dim=128, num_layers=6, nhead=8, ff_dim=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=4)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim, nhead=nhead, dim_feedforward=ff_dim,\n",
    "            dropout=dropout, batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.ln = nn.LayerNorm(emb_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(emb_dim, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, seq, lengths):\n",
    "        x = self.embed(seq)\n",
    "        mask = (seq == 4) \n",
    "        x = self.encoder(x, src_key_padding_mask=mask)\n",
    "        x = self.ln(x)\n",
    "        coords = self.fc(x)\n",
    "        return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "203ea1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_pts, total_rmsd = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for seqs, coords, lengths, _ in dataloader:\n",
    "            seqs, coords, lengths = seqs.to(device), coords.to(device), lengths.to(device)\n",
    "            pred_coords = model(seqs, lengths)\n",
    "            mask = torch.arange(seqs.size(1), device=device)[None, :] < lengths[:, None]\n",
    "            diff = ((pred_coords - coords) ** 2).sum(2).sqrt()\n",
    "            rmsd = (diff * mask).sum() / mask.sum()\n",
    "            total_rmsd += rmsd.item() * mask.sum().item()\n",
    "            total_pts += mask.sum().item()\n",
    "    mean_rmsd = total_rmsd / total_pts\n",
    "    print(f\"Validation RMSD: {mean_rmsd:.4f}\")\n",
    "    model.train()\n",
    "    return mean_rmsd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train_model(model, dataloader, device, epochs=100, lr=1e-3, val_loader=None, scheduler=None):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss(reduction='none')\n",
    "    best_val = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_points = 0\n",
    "        for seqs, coords, lengths, _ in dataloader:\n",
    "            seqs, coords, lengths = seqs.to(device), coords.to(device), lengths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred_coords = model(seqs, lengths)\n",
    "            mask = torch.arange(seqs.size(1), device=device)[None, :] < lengths[:, None]\n",
    "            mse = loss_fn(pred_coords, coords).sum(2)\n",
    "            loss = (mse * mask).sum() / mask.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * mask.sum().item()\n",
    "            total_points += mask.sum().item()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {running_loss/total_points:.5f}\")\n",
    "        if val_loader is not None:\n",
    "            val_rmsd = validate(model, val_loader, device)\n",
    "            if val_rmsd < best_val:\n",
    "                best_val = val_rmsd\n",
    "                torch.save(model.state_dict(), 'best_model.pt')\n",
    "                print(f\"Epoch {epoch+1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4c62a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission Function\n",
    "def submission(model, seq_csv, submission_csv, device, mean, std):\n",
    "    seq_df = pd.read_csv(seq_csv)\n",
    "    model.eval()\n",
    "    submissions = []\n",
    "    for idx, row in seq_df.iterrows():\n",
    "        target_id, sequence = row['target_id'], row['sequence'].strip()\n",
    "        seq_idx = torch.LongTensor([nt_to_idx.get(nt, 4) for nt in sequence]).unsqueeze(0).to(device)\n",
    "        lengths = torch.tensor([len(sequence)]).to(device)\n",
    "        with torch.no_grad():\n",
    "            coords = model(seq_idx, lengths)[0][:len(sequence)].cpu().numpy()\n",
    "            coords = coords * std + mean\n",
    "        for i, (nt, (x, y, z)) in enumerate(zip(sequence, coords)):\n",
    "            id_out = f\"{target_id}_{i+1}\"\n",
    "            submissions.append({\n",
    "                \"ID\": id_out,\n",
    "                \"resname\": nt,\n",
    "                \"resid\": i+1,\n",
    "                \"x_1\": x, \"y_1\": y, \"z_1\": z,\n",
    "                \"x_2\": 0.0, \"y_2\": 0.0, \"z_2\": 0.0,\n",
    "                \"x_3\": 0.0\n",
    "            })\n",
    "    sub_df = pd.DataFrame(submissions)\n",
    "    sub_df.to_csv(submission_csv, index=False)\n",
    "    print(f\"Submission CSV written: {submission_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f19a566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pradip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 4.29305\n",
      "Validation RMSD: 0.7969\n",
      "Epoch 1 (RMSD: 0.7969)\n",
      "Epoch 2 Loss: 3.70254\n",
      "Validation RMSD: 0.5413\n",
      "Epoch 2 (RMSD: 0.5413)\n",
      "Epoch 3 Loss: 3.51538\n",
      "Validation RMSD: 0.4722\n",
      "Epoch 3 (RMSD: 0.4722)\n",
      "Epoch 4 Loss: 3.43061\n",
      "Validation RMSD: 0.4680\n",
      "Epoch 4 (RMSD: 0.4680)\n",
      "Epoch 5 Loss: 3.41824\n",
      "Validation RMSD: 0.4176\n",
      "Epoch 5 (RMSD: 0.4176)\n",
      "Epoch 6 Loss: 3.40111\n",
      "Validation RMSD: 0.4111\n",
      "Epoch 6 (RMSD: 0.4111)\n",
      "Epoch 7 Loss: 3.37685\n",
      "Validation RMSD: 0.3853\n",
      "Epoch 7 (RMSD: 0.3853)\n",
      "Epoch 8 Loss: 3.35641\n",
      "Validation RMSD: 0.3971\n",
      "Epoch 9 Loss: 3.34937\n",
      "Validation RMSD: 0.4122\n",
      "Epoch 10 Loss: 3.33621\n",
      "Validation RMSD: 0.4468\n",
      "Epoch 11 Loss: 3.34375\n",
      "Validation RMSD: 0.4081\n",
      "Epoch 12 Loss: 3.31447\n",
      "Validation RMSD: 0.3344\n",
      "Epoch 12 (RMSD: 0.3344)\n",
      "Epoch 13 Loss: 3.30657\n",
      "Validation RMSD: 0.3692\n",
      "Epoch 14 Loss: 3.30667\n",
      "Validation RMSD: 0.3760\n",
      "Epoch 15 Loss: 3.29721\n",
      "Validation RMSD: 0.3636\n",
      "Epoch 16 Loss: 3.28375\n",
      "Validation RMSD: 0.3337\n",
      "Epoch 16 (RMSD: 0.3337)\n",
      "Epoch 17 Loss: 3.30761\n",
      "Validation RMSD: 0.3526\n",
      "Epoch 18 Loss: 3.28463\n",
      "Validation RMSD: 0.2646\n",
      "Epoch 18 (RMSD: 0.2646)\n",
      "Epoch 19 Loss: 3.26429\n",
      "Validation RMSD: 0.2886\n",
      "Epoch 20 Loss: 3.26305\n",
      "Validation RMSD: 0.3229\n",
      "Epoch 21 Loss: 3.26201\n",
      "Validation RMSD: 0.3324\n",
      "Epoch 22 Loss: 3.27023\n",
      "Validation RMSD: 0.3073\n",
      "Epoch 23 Loss: 3.25305\n",
      "Validation RMSD: 0.3120\n",
      "Epoch 24 Loss: 3.26018\n",
      "Validation RMSD: 0.3496\n",
      "Epoch 25 Loss: 3.25640\n",
      "Validation RMSD: 0.3090\n",
      "Epoch 26 Loss: 3.23553\n",
      "Validation RMSD: 0.3082\n",
      "Epoch 27 Loss: 3.24287\n",
      "Validation RMSD: 0.3112\n",
      "Epoch 28 Loss: 3.24507\n",
      "Validation RMSD: 0.2910\n",
      "Epoch 29 Loss: 3.23648\n",
      "Validation RMSD: 0.3376\n",
      "Epoch 30 Loss: 3.22776\n",
      "Validation RMSD: 0.3238\n",
      "Submission CSV written: rna-folding/submission.csv\n"
     ]
    }
   ],
   "source": [
    "#Training \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = RNAStruct(\"rna-folding/train_sequences_clean.csv\", \"rna-folding/train_labels_clean.csv\")\n",
    "val_dataset = RNAStruct(\"rna-folding/validation_sequences.csv\", \"rna-folding/validation_labels.csv\")\n",
    "\n",
    "mean = train_dataset.mean\n",
    "std = train_dataset.std\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=rna_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=rna_collate)\n",
    "\n",
    "model = RNA3DNet().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2) #CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "train_model(model, train_loader, device, epochs=30, lr=1e-5, val_loader=val_loader)\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "submission(model, \"rna-folding/test_sequences.csv\", \"rna-folding/submission.csv\", device, mean, std)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
