{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "42561c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "nt_to_idx = {'A': 0, 'U': 1, 'G': 2, 'C': 3, 'N': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615244fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ed86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNAStruct(Dataset):\n",
    "    def __init__(self, seq_csv, labels_csv):\n",
    "        seq_df = pd.read_csv(seq_csv)\n",
    "        seq_map = {row['target_id']: row['sequence'].strip() for _, row in seq_df.iterrows()}\n",
    "\n",
    "        labels_df = pd.read_csv(labels_csv)\n",
    "        self.data = {}\n",
    "        for _, row in labels_df.iterrows():\n",
    "            target_id = row['ID'].rsplit('_', 1)[0]\n",
    "            idx = int(row['resid']) - 1\n",
    "            if target_id not in self.data:\n",
    "                self.data[target_id] = []\n",
    "            self.data[target_id].append((idx, row['resname'], row['x_1'], row['y_1'], row['z_1']))\n",
    "\n",
    "        self.samples = []\n",
    "        all_coords = []\n",
    "        for target_id in self.data:\n",
    "            dat = sorted(self.data[target_id], key=lambda x: x[0])\n",
    "            seq = seq_map[target_id]\n",
    "            coords = np.array([[x[2], x[3], x[4]] for x in dat], dtype=np.float32)\n",
    "            if len(seq) == len(coords) and np.isfinite(coords).all():\n",
    "                seq_idx = np.array([nt_to_idx.get(nt, 4) for nt in seq], dtype=np.int64)\n",
    "                self.samples.append((target_id, seq_idx, coords))\n",
    "                all_coords.append(coords)\n",
    "            else:\n",
    "                print(f\"Bad entry removed: {target_id} (len/coords/finite)\")\n",
    "\n",
    "        all_coords = np.concatenate(all_coords, axis=0)\n",
    "        self.mean = np.mean(all_coords, axis=0)\n",
    "        self.std = np.std(all_coords, axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        target_id, seq_idx, coords = self.samples[idx]\n",
    "        norm_coords = (coords - self.mean) / self.std\n",
    "        return torch.LongTensor(seq_idx), torch.tensor(norm_coords), len(seq_idx), target_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "df5faf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate function\n",
    "def rna_collate(batch):\n",
    "    seqs, coords, lengths, ids = zip(*batch)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    seqs_padded = pad_sequence(seqs, batch_first=True, padding_value=4)\n",
    "    coords_padded = pad_sequence(coords, batch_first=True, padding_value=0)\n",
    "    return seqs_padded, coords_padded, lengths, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdff36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class RNA3DNet(nn.Module):\n",
    "    def __init__(self, vocab_size=5, emb_dim=128, num_layers=6, nhead=8, ff_dim=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=4)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=nhead, dim_feedforward=ff_dim, dropout=dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.ln = nn.LayerNorm(emb_dim)\n",
    "        self.fc = nn.Linear(emb_dim, 3)\n",
    "    def forward(self, seq, lengths):\n",
    "        x = self.embed(seq)\n",
    "        mask = (seq == 4)\n",
    "        x = self.encoder(x, src_key_padding_mask=mask)\n",
    "        x = self.ln(x)\n",
    "        coords = self.fc(x)\n",
    "        return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "671a9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, device, epochs=30, lr=1e-3, val_loader=None):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.8)\n",
    "    loss_fn = nn.MSELoss(reduction='none')\n",
    "    best_val_rmsd = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_points = 0\n",
    "        for seqs, coords, lengths, _ in dataloader:\n",
    "            seqs, coords, lengths = seqs.to(device), coords.to(device), lengths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred_coords = model(seqs, lengths)\n",
    "            mask = torch.arange(seqs.size(1), device=device)[None, :] < lengths[:, None]\n",
    "            mse = loss_fn(pred_coords, coords).sum(2)\n",
    "            loss = (mse * mask).sum() / mask.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * mask.sum().item()\n",
    "            total_points += mask.sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / total_points\n",
    "        print(f\"Epoch {epoch+1} Loss: {epoch_loss:.5f}\")\n",
    "\n",
    "        if val_loader is not None:\n",
    "            val_rmsd = validate(model, val_loader, device)\n",
    "            if val_rmsd is not None and val_rmsd < best_val_rmsd:\n",
    "                best_val_rmsd = val_rmsd\n",
    "                torch.save(model.state_dict(), 'best_model.pt')\n",
    "                print(f\"New best checkpoint (epoch {epoch+1}, RMSD {val_rmsd:.4f})\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    \n",
    "    torch.save(model.state_dict(), 'rna3dnet_baseline.pt')\n",
    "    print(\"Final model saved as rna3dnet_baseline.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f4c62a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission Function\n",
    "def submission(model, seq_csv, submission_csv, device, mean, std):\n",
    "    seq_df = pd.read_csv(seq_csv)\n",
    "    model.eval()\n",
    "    submissions = []\n",
    "    for idx, row in seq_df.iterrows():\n",
    "        target_id, sequence = row['target_id'], row['sequence'].strip()\n",
    "        seq_idx = torch.LongTensor([nt_to_idx.get(nt, 4) for nt in sequence]).unsqueeze(0).to(device)\n",
    "        lengths = torch.tensor([len(sequence)]).to(device)\n",
    "        with torch.no_grad():\n",
    "            coords = model(seq_idx, lengths)[0][:len(sequence)].cpu().numpy()\n",
    "            coords = coords * std + mean\n",
    "        for i, (nt, (x, y, z)) in enumerate(zip(sequence, coords)):\n",
    "            id_out = f\"{target_id}_{i+1}\"\n",
    "            submissions.append({\n",
    "                \"ID\": id_out,\n",
    "                \"resname\": nt,\n",
    "                \"resid\": i+1,\n",
    "                \"x_1\": x, \"y_1\": y, \"z_1\": z,\n",
    "                \"x_2\": 0.0, \"y_2\": 0.0, \"z_2\": 0.0,\n",
    "                \"x_3\": 0.0 \n",
    "            })\n",
    "    sub_df = pd.DataFrame(submissions)\n",
    "    sub_df.to_csv(submission_csv, index=False)\n",
    "    print(f\"Submission CSV written: {submission_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19a566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 3.60013\n",
      "Validation RMSD: 0.336\n",
      "Epoch 2 Loss: 3.27215\n",
      "Validation RMSD: 0.681\n",
      "Epoch 3 Loss: 3.10564\n",
      "Validation RMSD: 0.520\n",
      "Epoch 4 Loss: 3.21520\n",
      "Validation RMSD: 1.177\n",
      "Epoch 5 Loss: 3.56804\n",
      "Validation RMSD: 0.791\n",
      "Epoch 6 Loss: 3.27372\n",
      "Validation RMSD: 0.291\n",
      "Epoch 7 Loss: 3.11177\n",
      "Validation RMSD: 0.585\n",
      "Epoch 8 Loss: 3.35639\n",
      "Validation RMSD: 0.283\n",
      "Epoch 9 Loss: 3.25554\n",
      "Validation RMSD: 0.448\n",
      "Epoch 10 Loss: 3.03878\n",
      "Validation RMSD: 0.466\n",
      "Epoch 11 Loss: 3.15604\n",
      "Validation RMSD: 0.335\n",
      "Epoch 12 Loss: 3.09856\n",
      "Validation RMSD: 0.908\n",
      "Epoch 13 Loss: 3.22699\n",
      "Validation RMSD: 0.388\n",
      "Epoch 14 Loss: 3.01949\n",
      "Validation RMSD: 0.463\n",
      "Epoch 15 Loss: 2.95320\n",
      "Validation RMSD: 0.466\n",
      "Epoch 16 Loss: 3.04773\n",
      "Validation RMSD: 0.329\n",
      "Epoch 17 Loss: 3.01918\n",
      "Validation RMSD: 0.490\n",
      "Epoch 18 Loss: 3.02901\n",
      "Validation RMSD: 0.613\n",
      "Epoch 19 Loss: 3.10907\n",
      "Validation RMSD: 0.496\n",
      "Epoch 20 Loss: 3.01591\n",
      "Validation RMSD: 0.474\n",
      "Epoch 21 Loss: 2.98322\n",
      "Validation RMSD: 0.307\n",
      "Epoch 22 Loss: 2.96907\n",
      "Validation RMSD: 0.296\n",
      "Epoch 23 Loss: 3.00900\n",
      "Validation RMSD: 0.347\n",
      "Epoch 24 Loss: 2.99050\n",
      "Validation RMSD: 0.502\n",
      "Epoch 25 Loss: 2.98472\n",
      "Validation RMSD: 0.456\n",
      "Epoch 26 Loss: 3.02005\n",
      "Validation RMSD: 0.453\n",
      "Epoch 27 Loss: 3.03917\n",
      "Validation RMSD: 0.505\n",
      "Epoch 28 Loss: 2.95966\n",
      "Validation RMSD: 0.567\n",
      "Epoch 29 Loss: 2.91873\n",
      "Validation RMSD: 0.374\n",
      "Epoch 30 Loss: 2.84459\n",
      "Validation RMSD: 0.506\n",
      "Final model saved as rna3dnet_baseline.pt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m RNA3DNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m train_model(model, train_loader, device, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, val_loader\u001b[38;5;241m=\u001b[39mval_loader)\n\u001b[1;32m---> 17\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n\u001b[0;32m     20\u001b[0m submission(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrna-folding/test_sequences.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrna-folding/submission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, device, mean, std)\n",
      "File \u001b[1;32mc:\\Users\\Pradip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Pradip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Pradip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_model.pt'"
     ]
    }
   ],
   "source": [
    "#Training \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = RNAStruct(\"rna-folding/train_sequences_clean.csv\", \"rna-folding/train_labels_clean.csv\")\n",
    "val_dataset = RNAStruct(\"rna-folding/validation_sequences.csv\", \"rna-folding/validation_labels.csv\")\n",
    "\n",
    "mean = train_dataset.mean\n",
    "std = train_dataset.std\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=rna_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=rna_collate)\n",
    "\n",
    "model = RNA3DNet().to(device)\n",
    "train_model(model, train_loader, device, epochs=30, lr=5e-4, val_loader=val_loader)\n",
    "\n",
    "model.load_state_dict(torch.load('rna3dnet_baseline.pt'))\n",
    "\n",
    "# Generate predictions\n",
    "submission(model, \"rna-folding/test_sequences.csv\", \"rna-folding/submission.csv\", device, mean, std)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
